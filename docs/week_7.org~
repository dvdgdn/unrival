#+TITLE: Promise Protocol v1 ‚Äî The Guided Tour
#+SUBTITLE: Week 7 of 12: The Living Scorecard & Replication
#+AUTHOR: Your Software Pedagogue
#+TODO: TODO(t) IN-PROGRESS(i) | DONE(d) CANCELED(c)
#+OPTIONS: toc:2 num:t ^:nil

* This Week's Mission üéØ
Last week, we built our Assessment Engine and began our deep dive into the theory of distributed coordination. This week, we will connect that theory directly to our work by building the "living" part of the system‚Äîthe `Scorecard` that evolves over time. Our mission is to implement a score that isn't static but changes with *decay* and is rewarded with *forgiveness*. In parallel, we will complete our study of core coordination by learning about *data replication*, which will connect all the theoretical dots from the past two weeks.

* Learning Plan üìö
With a solid understanding of time and leader election, you are now ready to tackle the main event: making multiple machines agree on the same data.

** TODO Reading Assignment
   - [ ] Read *Chapter 10: Replication* in /Understanding Distributed Systems/.
     - *Focus On*:
       - [cite_start]*State Machine Replication (10.1)*[cite: 1243]: This is the core concept. [cite_start]Understand that if you have a group of identical, deterministic state machines and you give them the same inputs in the same order, they will all end up in the same state[cite: 1253]. This is the "why" behind the deterministic DSL you built last week.
       - [cite_start]*The Replicated Log*: Grasp that the leader achieves consensus by first writing operations to an ordered log and then replicating that log to its followers[cite: 1269].
       - [cite_start]*Consistency Models (10.3)*[cite: 1409]: Pay close attention to the difference between strong, sequential, and eventual consistency. This is a fundamental trade-off in nearly every distributed system.
     - /Why this now?/: This chapter is the culmination of your theoretical work on coordination. It directly builds on leader election (Ch 9) and failure detection (Ch 7) to show how a robust, fault-tolerant system can be built.

* Building Plan: A Step-by-Step Guide üõ†Ô∏è
This week's build is all about the `Scorecard` (Original Step 8). The main challenge is correctly handling the time-based logic.

** TODO [#A] Step 7.1: Write the BDD Feature Test for the Scorecard's Lifecycle
   Our test must tell a story that unfolds over time. We'll use our `FixedClock` to jump forward and verify that the score changes as expected.

   - [ ] Create a new Gherkin feature file for the Scorecard's evolution.
   - [ ] Write the scenario that uses time-travel to test decay and forgiveness.
     #+BEGIN_SRC gherkin
     Feature: A Scorecard that Evolves Over Time

       Scenario: A coach's score decays and is rewarded for monthly consistency
         Given a coach has a Reliability Index (RI) score of 0.850 on October 25th, 2025
         And this coach has had zero breaches in October

         When the system Clock advances to November 1st, 2025
         And the daily scoring job runs
         Then the "Monthly Forgiveness" bonus for their perfect October record is applied
         And their new RI score is 0.900

         When the system Clock advances another 30 days to December 1st, 2025
         And the coach had two minor breaches in November
         And the daily scoring job runs
         Then their RI score has decayed due to the passage of time and the new breaches
         And the "Monthly Forgiveness" bonus is *not* applied
     #+END_SRC

** TODO [#B] Step 7.2: Implement the `Scorecard` Aggregate
   This is the core domain model for a coach's reputation. Like the `Session` aggregate, it must protect its own rules.

   - [ ] Create the =Scorecard.ts= aggregate root class.
   - [ ] Implement an `applyDelta()` method that takes an `AssessmentResult` and updates the internal score.
   - [ ] Implement a `decayTo(now: Date)` method that calculates and applies score decay based on the time elapsed since the last update.
   - [ ] Implement a `monthlyForgiveness(now: Date)` method that checks for a perfect record in the previous month and applies a bonus.

** TODO [#B] Step 7.3: Implement the Time-Based Logic
   Here we add the dynamic behavior that makes the scorecard "live."

   - *Key Concept: Exponential Decay*. The impact of old events should fade over time. A good analogy is a *cup of hot coffee cooling down* ‚òï. It loses heat fastest at the beginning and the rate of cooling slows down as it approaches room temperature. Your decay function should ensure recent behavior matters most. 
   - [ ] Inside your `decayTo` method, implement an exponential decay formula. This will require the `Clock` to know what "now" is.
   - [ ] Inside the `monthlyForgiveness` method, use the `Clock` to determine month boundaries and query for breaches within that calendar month.

** TODO [#C] Step 7.4: Implement the Idempotent Background Job
   This job will run periodically (e.g., daily) to update all scorecards.

   - *Key Concept: Idempotent Job*. This daily job is like taking a *daily vitamin* üíä. You should only get the benefit once per day. If the job runner accidentally runs the job for "September 16th" twice, it must not apply decay twice.
   - [ ] Create a new job handler, e.g., =ApplyDailyDecayHandler=.
   - [ ] This handler will be triggered by a scheduler (e.g., a simple cron process).
   - [ ] The handler will fetch a batch of scorecards, call the `decayTo(now)` and `monthlyForgiveness(now)` methods on each, and save them back to the database.
   - [ ] Ensure the job is idempotent by using a key (e.g., the date =2025-09-16=) to track that the day's decay has already been successfully applied.

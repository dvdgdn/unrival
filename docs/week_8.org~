#+TITLE: Promise Protocol v1 ‚Äî The Guided Tour
#+SUBTITLE: Week 8 of 12: The Full Picture
#+AUTHOR: Your Software Pedagogue
#+TODO: TODO(t) IN-PROGRESS(i) | DONE(d) CANCELED(c)
#+OPTIONS: toc:2 num:t ^:nil

* This Week's Mission üéØ
Last week, we built a dynamic `Scorecard` and completed our study of data replication. This week, our mission is to create the "full picture" by composing our various scores into a single, meaningful *Overall Awesome Score (OAS)*. We will not just calculate this score, but also build the logic to present it responsibly, hiding it until we have enough data to be confident in its accuracy. This work will be informed by our final reading on coordination, which explores how to build highly available systems that don't require a central leader.

* Learning Plan üìö
This is the capstone reading for Part II of the book. It introduces a different way of thinking about consistency that is highly relevant to modern, large-scale applications.

** TODO Reading Assignment
   - [ ] Read *Chapter 11: Coordination avoidance* in /Understanding Distributed Systems/.
     - *Focus On*:
       - The concept of *eventual consistency* and *strong eventual consistency*.
       - How *Conflict-free Replicated Data Types (CRDTs)* allow systems to converge on a correct state without a leader by designing operations to be commutative.
       - The high-level design of *Dynamo-style data stores* that prioritize availability.
     - /Why this now?/: This chapter provides the deep theoretical context for the practical problem you're solving this week. The "minimum sample size" rule for displaying the OAS is a direct application of dealing with a system where data is not yet fully consistent or representative.

* Building Plan: A Step-by-Step Guide üõ†Ô∏è
This week, we will implement the original Step 9 from the plan, enriching our scoring model and adding the final layer of intelligence.

** TODO [#A] Step 8.1: Write the BDD Feature Test for the OAS
   The most important rule for the OAS is not its calculation, but its responsible presentation. Our tests will focus on this display logic.

   - [ ] Create a new Gherkin feature file for the OAS.
   - [ ] Write the scenarios that define the minimum sample size and confidence labeling.
     #+BEGIN_SRC gherkin
     Feature: Overall Awesome Score (OAS) is Displayed Responsibly

       Scenario: OAS is hidden until 3 sessions with subjective evidence are complete
         Given a coach has completed only 2 sessions with subjective evidence
         When a user views that coach's scorecard
         Then the Overall Awesome Score (OAS) section is hidden
         And a helper text is displayed, saying "Overall Score is shown after 3 sessions."

       Scenario: OAS appears with a confidence label after the threshold is met
         Given a coach has just completed their 3rd session with subjective evidence
         When a user views that coach's scorecard
         Then the Overall Awesome Score (OAS) section is now visible
         And the calculated OAS is displayed with a "Low Confidence" label
     #+END_SRC

** TODO [#B] Step 8.2: Implement Additional Standards
   To make the OAS more meaningful, we first need to broaden the inputs we can assess.

   - [ ] Implement a new standard, "Recap ‚â§24h," in your Assessment Engine.
   - [ ] This involves defining the new DSL rule, ensuring the parser can handle it, and adding the logic to the evaluator.
   - [ ] Write unit tests for the new standard to ensure it is evaluated correctly.

** TODO [#C] Step 8.3: Implement the OAS Composition Logic
   Now, we'll combine our various scores into one.

   - *Key Concept: Weighted Sums*. This is like *calculating a final grade in a class*. The homework, midterm, and final exam all contribute to the final grade, but they have different levels of importance or "weights."
     #+CAPTION: Example OAS Calculation
     | Component         | Score | Weight | Contribution |
     |-------------------+-------+--------+--------------|
     | Reliability Index |  0.90 |   0.60 |         0.54 |
     | Efficacy Index    |  0.85 |   0.40 |         0.34 |
     | *Final OAS* |       |        |         *0.88* |
   - [ ] Create a new service or method responsible for calculating the OAS.
   - [ ] This logic will fetch the component scores (RI, EI, etc.) from a `Scorecard` object.
   - [ ] It will then apply a weighted formula (e.g., `OAS = (RI * 0.6) + (EI * 0.4)`) to produce the final score.

** TODO [#C] Step 8.4: Implement Confidence and Display Rules
   Finally, we implement the responsible presentation logic defined in our BDD test.

   - *Key Concept: Minimum Sample Size*. This is like a *movie review website*. It won't show a "100% Fresh" score based on one single review. It waits for a minimum number of reviews to avoid presenting a misleading score.
   - *Key Concept: Confidence Tiers*. This is like forming an opinion of a *new restaurant*. A recommendation from one friend is "Low Confidence." Recommendations from 200 online reviews and all your friends is "High Confidence."
   - [ ] In the Application layer logic that prepares the data for the API...
   - [ ] ...first, check the number of sessions with subjective evidence for the given coach.
   - [ ] If the count is less than 3, do not include the OAS in the data sent to the client.
   - [ ] If the count is 3 or more, calculate the OAS *and* determine the confidence label (e.g., 3-5 sessions = "Low", 6-15 = "Medium", 16+ = "High") to send along with the score.
